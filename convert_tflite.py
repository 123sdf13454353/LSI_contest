from config import load_model, tqdm, Fxp, np, cv2, os, glob,plt
from dataset import load_dataset
import time
import tensorflow as tf

# Load mÃ´ hÃ¬nh Keras
x_train_new, x_test, x_good, x_cut, x_train, x_hole, x_print = load_dataset()

encoder_fixedpoint = tf.keras.models.load_model('vae_encoder_fixedpoint.h5')
decoder_fixedpoint = tf.keras.models.load_model('vae_decoder_fixedpoint.h5')

converter_encoder = tf.lite.TFLiteConverter.from_keras_model(encoder_fixedpoint)
converter_decoder = tf.lite.TFLiteConverter.from_keras_model(decoder_fixedpoint)

# Chuyá»ƒn Ä‘á»•i mÃ´ hÃ¬nh sang TFLite mÃ  khÃ´ng lÆ°á»£ng tá»­ hÃ³a
tflite_model_encoder = converter_encoder.convert()
tflite_model_decoder = converter_decoder.convert()

# LÆ°u model TFLite
with open('model_encoder_float.tflite', 'wb') as f:
    f.write(tflite_model_encoder)

with open('model_decoder_float.tflite', 'wb') as f:
    f.write(tflite_model_decoder)

print("âœ… MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i sang .tflite mÃ  khÃ´ng Ã¡p dá»¥ng lÆ°á»£ng tá»­ hÃ³a!")

# Load mÃ´ hÃ¬nh TFLite (Encoder vÃ  Decoder riÃªng biá»‡t)
interpreter_encoder = tf.lite.Interpreter(model_path='model_encoder_float.tflite')
interpreter_decoder = tf.lite.Interpreter(model_path='model_decoder_float.tflite')

interpreter_encoder.allocate_tensors()
interpreter_decoder.allocate_tensors()

# Láº¥y thÃ´ng tin tensor input vÃ  output
encoder_input_details = interpreter_encoder.get_input_details()
encoder_output_details = interpreter_encoder.get_output_details()

decoder_input_details = interpreter_decoder.get_input_details()
decoder_output_details = interpreter_decoder.get_output_details()

# Chuyá»ƒn input vá» Ä‘Ãºng dtype (FLOAT32)
input_data = np.array([x_print[0]], dtype=np.float32)  # Giá»¯ nguyÃªn shape nhÆ°ng Ä‘á»•i dtype

# Äá»“ng bá»™ hÃ³a CPU trÆ°á»›c khi Ä‘o thá»i gian
tf.keras.backend.clear_session()

# ğŸ•’ Báº¯t Ä‘áº§u Ä‘o thá»i gian inference
start_time = time.perf_counter()

# ÄÆ°a dá»¯ liá»‡u vÃ o Encoder
interpreter_encoder.set_tensor(encoder_input_details[0]['index'], input_data)
interpreter_encoder.invoke()

# Láº¥y output tá»« Encoder (latent vector)
latent_vector = interpreter_encoder.get_tensor(encoder_output_details[0]['index'])

# ÄÆ°a latent vector vÃ o Decoder
interpreter_decoder.set_tensor(decoder_input_details[0]['index'], latent_vector)
interpreter_decoder.invoke()

# Láº¥y áº£nh tÃ¡i táº¡o tá»« Decoder
reconstructed_image = interpreter_decoder.get_tensor(decoder_output_details[0]['index'])

end_time = time.perf_counter()

# TÃ­nh thá»i gian inference
inference_time = end_time - start_time

# Chuyá»ƒn Ä‘á»•i thÃ nh giá», phÃºt, giÃ¢y
hours = int(inference_time // 3600)
minutes = int((inference_time % 3600) // 60)
seconds = inference_time % 60  # Giá»¯ pháº§n tháº­p phÃ¢n cho giÃ¢y

# ğŸ“ In káº¿t quáº£
print(f"Thá»i gian suy luáº­n: {hours} giá», {minutes} phÃºt, {seconds:.3f} giÃ¢y")
print(f"Trung bÃ¬nh má»—i áº£nh: {inference_time:.3f} giÃ¢y")

# Hiá»ƒn thá»‹ áº£nh gá»‘c vÃ  áº£nh tÃ¡i táº¡o tá»« mÃ´ hÃ¬nh
fig, axes = plt.subplots(1, 2, figsize=(10, 5))

# áº¢nh gá»‘c
axes[0].imshow(x_print[0], cmap='gray')  # Náº¿u áº£nh lÃ  grayscale, sá»­ dá»¥ng cmap='gray'
axes[0].set_title("áº¢nh gá»‘c")
axes[0].axis("off")

# áº¢nh tÃ¡i táº¡o
axes[1].imshow(reconstructed_image[0], cmap='gray')  # Náº¿u áº£nh lÃ  grayscale, sá»­ dá»¥ng cmap='gray'
axes[1].set_title("áº¢nh tÃ¡i táº¡o")
axes[1].axis("off")

plt.show()
